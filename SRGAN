{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":588358,"sourceType":"datasetVersion","datasetId":286056}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Ensure we only see one GPU (if you want to enforce single-GPU usage)\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    print(f\"Using GPU: {physical_devices[0]}\")\nelse:\n    print(\"No GPU found. Using CPU.\")\n\n# Set random seeds for reproducibility\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nprint(f\"TensorFlow version: {tf.__version__}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-03-19T19:33:29.306285Z","iopub.execute_input":"2025-03-19T19:33:29.306659Z","iopub.status.idle":"2025-03-19T19:33:40.737146Z","shell.execute_reply.started":"2025-03-19T19:33:29.306631Z","shell.execute_reply":"2025-03-19T19:33:40.736392Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\nTensorFlow version: 2.13.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"class SRGANConfig:\n    def __init__(self):\n        # Dataset parameters\n        self.dataset_name = \"DIV2K\"\n        self.data_dir = \"../input/div2k-dataset/DIV2K_train_HR/DIV2K_train_HR\"\n        self.val_dir = \"../input/div2k-dataset/DIV2K_valid_HR/DIV2K_valid_HR\"\n\n        # High-resolution (HR) dimensions\n        self.hr_height = 256\n        self.hr_width = 256\n        \n        # Scale factor for SR\n        self.scale_factor = 4\n        self.lr_height = self.hr_height // self.scale_factor\n        self.lr_width = self.hr_width // self.scale_factor\n        \n        # Training parameters\n        self.epochs = 200\n        self.batch_size = 16\n        self.gen_lr = 1e-4\n        self.disc_lr = 1e-4\n        self.beta1 = 0.5\n        \n        # Model parameters\n        self.gen_filters = 64\n        self.disc_filters = 64\n        self.num_res_blocks = 16\n        \n        # Loss weights\n        self.content_weight = 1.0          # for pixel-based loss\n        self.perceptual_weight = 0.006     # for VGG-based perceptual loss\n        self.adversarial_weight = 1e-3     # for generator adversarial loss\n        \n        # Paths for saving artifacts\n        self.checkpoint_dir = \"checkpoints\"\n        self.sample_dir = \"samples\"\n        \n        os.makedirs(self.checkpoint_dir, exist_ok=True)\n        os.makedirs(self.sample_dir, exist_ok=True)\n\nconfig = SRGANConfig()\nprint(\"SRGANConfig loaded.\")\n\n\nclass DataLoader:\n    \"\"\"\n    Prepares training and validation datasets from DIV2K or similar directories.\n    Assumes .png files, randomly crops HR images, and resizes to LR.\n    \"\"\"\n    def __init__(self, config):\n        self.config = config\n        \n    def _verify_paths(self):\n        if not tf.io.gfile.exists(self.config.data_dir):\n            raise ValueError(f\"Training directory {self.config.data_dir} does not exist\")\n        if not tf.io.gfile.exists(self.config.val_dir):\n            raise ValueError(f\"Validation directory {self.config.val_dir} does not exist\")\n            \n        train_files = tf.io.gfile.glob(os.path.join(self.config.data_dir, \"*.png\"))\n        val_files = tf.io.gfile.glob(os.path.join(self.config.val_dir, \"*.png\"))\n        \n        if not train_files:\n            raise ValueError(f\"No PNG files found in {self.config.data_dir}\")\n        if not val_files:\n            raise ValueError(f\"No PNG files found in {self.config.val_dir}\")\n            \n        return len(train_files), len(val_files)\n    \n    def load_and_preprocess(self, image_path):\n        # Read file and decode PNG\n        img = tf.io.read_file(image_path)\n        img = tf.image.decode_png(img, channels=3)\n        \n        # Random crop to a fixed HR patch (256x256)\n        img = tf.image.random_crop(\n            img, [self.config.hr_height, self.config.hr_width, 3]\n        )\n        img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n        \n        # Create low-res version (64x64 if scale=4)\n        lr_img = tf.image.resize(\n            img, [self.config.lr_height, self.config.lr_width],\n            method='bicubic'\n        )\n        return lr_img, img\n    \n    def create_dataset(self, is_training=True):\n        train_count, val_count = self._verify_paths()\n        \n        if is_training:\n            # Training set\n            files = tf.data.Dataset.list_files(\n                os.path.join(self.config.data_dir, \"*.png\"),\n                shuffle=True\n            )\n            print(f\"Found {train_count} training images.\")\n        else:\n            # Validation set\n            files = tf.data.Dataset.list_files(\n                os.path.join(self.config.val_dir, \"*.png\"),\n                shuffle=False\n            )\n            print(f\"Found {val_count} validation images.\")\n        \n        # Map function\n        dataset = files.map(self.load_and_preprocess,\n                            num_parallel_calls=tf.data.AUTOTUNE)\n        \n        # Batch, prefetch\n        dataset = dataset.batch(self.config.batch_size)\n        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n        return dataset\n\n# Usage: \ndata_loader = DataLoader(config)\ntrain_dataset = data_loader.create_dataset(is_training=True)\nval_dataset = data_loader.create_dataset(is_training=False)","metadata":{"execution":{"iopub.status.busy":"2025-03-19T19:50:18.237411Z","iopub.execute_input":"2025-03-19T19:50:18.238406Z","iopub.status.idle":"2025-03-19T19:50:18.541285Z","shell.execute_reply.started":"2025-03-19T19:50:18.238373Z","shell.execute_reply":"2025-03-19T19:50:18.540448Z"},"trusted":true},"outputs":[{"name":"stdout","text":"SRGANConfig loaded.\nFound 800 training images.\nFound 100 validation images.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from tensorflow.keras.mixed_precision import set_global_policy\n\n# Use mixed precision for faster training on GPUs that support it\nset_global_policy('mixed_float16')\n\ndef residual_block(x, filters):\n    \"\"\"\n    Residual block: Conv -> BN -> PReLU -> Conv -> BN -> Add skip\n    \"\"\"\n    shortcut = x\n    x = layers.Conv2D(filters, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.PReLU(shared_axes=[1, 2])(x)\n    x = layers.Conv2D(filters, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Add()([shortcut, x])\n    return x\n\ndef upsample_block(x, filters):\n    \"\"\"\n    Upsampling via sub-pixel (depth_to_space).\n    Conv2D(filters*4) -> tf.nn.depth_to_space -> PReLU\n    \"\"\"\n    x = layers.Conv2D(filters * 4, 3, padding='same')(x)\n    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)\n    x = layers.PReLU(shared_axes=[1, 2])(x)\n    return x\n\ndef build_generator(config):\n    \"\"\"\n    SRGAN Generator (SRResNet backbone)\n    Input: (lr_height, lr_width, 3) -> Output: (hr_height, hr_width, 3)\n    \"\"\"\n    inputs = layers.Input(shape=(config.lr_height, config.lr_width, 3))\n    # Initial Conv\n    x = layers.Conv2D(64, 9, padding='same')(inputs)\n    x = layers.PReLU(shared_axes=[1, 2])(x)\n    skip = x\n\n    # Residual blocks\n    for _ in range(config.num_res_blocks):\n        x = residual_block(x, config.gen_filters)\n\n    # Conv + BN, then add skip\n    x = layers.Conv2D(64, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Add()([skip, x])\n\n    # Upsampling blocks (2x each => total 4x)\n    for _ in range(2):\n        x = upsample_block(x, 64)\n\n    # Final conv -> Tanh -> shift to [0,1]\n    x = layers.Conv2D(3, 9, padding='same', activation='tanh')(x)\n    outputs = layers.Lambda(lambda x: (x + 1) / 2)(x)\n\n    return keras.Model(inputs, outputs)\n\ngenerator = build_generator(config)\ngenerator.summary()\n\ndef build_discriminator(config):\n    \"\"\"\n    SRGAN Discriminator\n    Input: (hr_height, hr_width, 3) -> Output: Real/Fake\n    \"\"\"\n    inputs = layers.Input(shape=(config.hr_height, config.hr_width, 3))\n    # Initial layer\n    x = layers.Conv2D(64, kernel_size=3, strides=1, padding=\"same\")(inputs)\n    x = layers.LeakyReLU(alpha=0.2)(x)\n\n    filters = 64\n    for i in range(4):\n        stride = 2 if i % 2 == 0 else 1\n        filters = min(filters * 2, 512)\n        x = layers.Conv2D(filters, kernel_size=3, strides=stride, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.LeakyReLU(alpha=0.2)(x)\n\n    # Classification layers\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(1024)(x)\n    x = layers.LeakyReLU(alpha=0.2)(x)\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n\n    return keras.Model(inputs, outputs)\n\ndiscriminator = build_discriminator(config)\ndiscriminator.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:37:22.750141Z","iopub.execute_input":"2025-03-19T19:37:22.750820Z","iopub.status.idle":"2025-03-19T19:37:24.247587Z","shell.execute_reply.started":"2025-03-19T19:37:22.750794Z","shell.execute_reply":"2025-03-19T19:37:24.246701Z"}},"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 64, 64, 64)           15616     ['input_1[0][0]']             \n                                                                                                  \n p_re_lu (PReLU)             (None, 64, 64, 64)           64        ['conv2d[0][0]']              \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['p_re_lu[0][0]']             \n                                                                                                  \n batch_normalization (Batch  (None, 64, 64, 64)           256       ['conv2d_1[0][0]']            \n Normalization)                                                                                   \n                                                                                                  \n p_re_lu_1 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 64, 64, 64)           36928     ['p_re_lu_1[0][0]']           \n                                                                                                  \n batch_normalization_1 (Bat  (None, 64, 64, 64)           256       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n add (Add)                   (None, 64, 64, 64)           0         ['p_re_lu[0][0]',             \n                                                                     'batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 64, 64, 64)           36928     ['add[0][0]']                 \n                                                                                                  \n batch_normalization_2 (Bat  (None, 64, 64, 64)           256       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n p_re_lu_2 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 64, 64, 64)           36928     ['p_re_lu_2[0][0]']           \n                                                                                                  \n batch_normalization_3 (Bat  (None, 64, 64, 64)           256       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n add_1 (Add)                 (None, 64, 64, 64)           0         ['add[0][0]',                 \n                                                                     'batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 64, 64, 64)           36928     ['add_1[0][0]']               \n                                                                                                  \n batch_normalization_4 (Bat  (None, 64, 64, 64)           256       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n p_re_lu_3 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 64, 64, 64)           36928     ['p_re_lu_3[0][0]']           \n                                                                                                  \n batch_normalization_5 (Bat  (None, 64, 64, 64)           256       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n add_2 (Add)                 (None, 64, 64, 64)           0         ['add_1[0][0]',               \n                                                                     'batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 64, 64, 64)           36928     ['add_2[0][0]']               \n                                                                                                  \n batch_normalization_6 (Bat  (None, 64, 64, 64)           256       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n p_re_lu_4 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 64, 64, 64)           36928     ['p_re_lu_4[0][0]']           \n                                                                                                  \n batch_normalization_7 (Bat  (None, 64, 64, 64)           256       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n add_3 (Add)                 (None, 64, 64, 64)           0         ['add_2[0][0]',               \n                                                                     'batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 64, 64, 64)           36928     ['add_3[0][0]']               \n                                                                                                  \n batch_normalization_8 (Bat  (None, 64, 64, 64)           256       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n p_re_lu_5 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_5[0][0]']           \n                                                                                                  \n batch_normalization_9 (Bat  (None, 64, 64, 64)           256       ['conv2d_10[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n add_4 (Add)                 (None, 64, 64, 64)           0         ['add_3[0][0]',               \n                                                                     'batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 64, 64, 64)           36928     ['add_4[0][0]']               \n                                                                                                  \n batch_normalization_10 (Ba  (None, 64, 64, 64)           256       ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_6 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_6[0][0]']           \n                                                                                                  \n batch_normalization_11 (Ba  (None, 64, 64, 64)           256       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_5 (Add)                 (None, 64, 64, 64)           0         ['add_4[0][0]',               \n                                                                     'batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 64, 64, 64)           36928     ['add_5[0][0]']               \n                                                                                                  \n batch_normalization_12 (Ba  (None, 64, 64, 64)           256       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_7 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_7[0][0]']           \n                                                                                                  \n batch_normalization_13 (Ba  (None, 64, 64, 64)           256       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_6 (Add)                 (None, 64, 64, 64)           0         ['add_5[0][0]',               \n                                                                     'batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 64, 64, 64)           36928     ['add_6[0][0]']               \n                                                                                                  \n batch_normalization_14 (Ba  (None, 64, 64, 64)           256       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_8 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_8[0][0]']           \n                                                                                                  \n batch_normalization_15 (Ba  (None, 64, 64, 64)           256       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_7 (Add)                 (None, 64, 64, 64)           0         ['add_6[0][0]',               \n                                                                     'batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 64, 64, 64)           36928     ['add_7[0][0]']               \n                                                                                                  \n batch_normalization_16 (Ba  (None, 64, 64, 64)           256       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_9 (PReLU)           (None, 64, 64, 64)           64        ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_9[0][0]']           \n                                                                                                  \n batch_normalization_17 (Ba  (None, 64, 64, 64)           256       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_8 (Add)                 (None, 64, 64, 64)           0         ['add_7[0][0]',               \n                                                                     'batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 64, 64, 64)           36928     ['add_8[0][0]']               \n                                                                                                  \n batch_normalization_18 (Ba  (None, 64, 64, 64)           256       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_10 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_10[0][0]']          \n                                                                                                  \n batch_normalization_19 (Ba  (None, 64, 64, 64)           256       ['conv2d_20[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_9 (Add)                 (None, 64, 64, 64)           0         ['add_8[0][0]',               \n                                                                     'batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 64, 64, 64)           36928     ['add_9[0][0]']               \n                                                                                                  \n batch_normalization_20 (Ba  (None, 64, 64, 64)           256       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_11 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_11[0][0]']          \n                                                                                                  \n batch_normalization_21 (Ba  (None, 64, 64, 64)           256       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_10 (Add)                (None, 64, 64, 64)           0         ['add_9[0][0]',               \n                                                                     'batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 64, 64, 64)           36928     ['add_10[0][0]']              \n                                                                                                  \n batch_normalization_22 (Ba  (None, 64, 64, 64)           256       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_12 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_12[0][0]']          \n                                                                                                  \n batch_normalization_23 (Ba  (None, 64, 64, 64)           256       ['conv2d_24[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_11 (Add)                (None, 64, 64, 64)           0         ['add_10[0][0]',              \n                                                                     'batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 64, 64, 64)           36928     ['add_11[0][0]']              \n                                                                                                  \n batch_normalization_24 (Ba  (None, 64, 64, 64)           256       ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_13 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_13[0][0]']          \n                                                                                                  \n batch_normalization_25 (Ba  (None, 64, 64, 64)           256       ['conv2d_26[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_12 (Add)                (None, 64, 64, 64)           0         ['add_11[0][0]',              \n                                                                     'batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 64, 64, 64)           36928     ['add_12[0][0]']              \n                                                                                                  \n batch_normalization_26 (Ba  (None, 64, 64, 64)           256       ['conv2d_27[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_14 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_14[0][0]']          \n                                                                                                  \n batch_normalization_27 (Ba  (None, 64, 64, 64)           256       ['conv2d_28[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_13 (Add)                (None, 64, 64, 64)           0         ['add_12[0][0]',              \n                                                                     'batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 64, 64, 64)           36928     ['add_13[0][0]']              \n                                                                                                  \n batch_normalization_28 (Ba  (None, 64, 64, 64)           256       ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_15 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_15[0][0]']          \n                                                                                                  \n batch_normalization_29 (Ba  (None, 64, 64, 64)           256       ['conv2d_30[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_14 (Add)                (None, 64, 64, 64)           0         ['add_13[0][0]',              \n                                                                     'batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 64, 64, 64)           36928     ['add_14[0][0]']              \n                                                                                                  \n batch_normalization_30 (Ba  (None, 64, 64, 64)           256       ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n p_re_lu_16 (PReLU)          (None, 64, 64, 64)           64        ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 64, 64, 64)           36928     ['p_re_lu_16[0][0]']          \n                                                                                                  \n batch_normalization_31 (Ba  (None, 64, 64, 64)           256       ['conv2d_32[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_15 (Add)                (None, 64, 64, 64)           0         ['add_14[0][0]',              \n                                                                     'batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 64, 64, 64)           36928     ['add_15[0][0]']              \n                                                                                                  \n batch_normalization_32 (Ba  (None, 64, 64, 64)           256       ['conv2d_33[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_16 (Add)                (None, 64, 64, 64)           0         ['p_re_lu[0][0]',             \n                                                                     'batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 64, 64, 256)          147712    ['add_16[0][0]']              \n                                                                                                  \n lambda (Lambda)             (None, 128, 128, 64)         0         ['conv2d_34[0][0]']           \n                                                                                                  \n p_re_lu_17 (PReLU)          (None, 128, 128, 64)         64        ['lambda[0][0]']              \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 128, 128, 256)        147712    ['p_re_lu_17[0][0]']          \n                                                                                                  \n lambda_1 (Lambda)           (None, 256, 256, 64)         0         ['conv2d_35[0][0]']           \n                                                                                                  \n p_re_lu_18 (PReLU)          (None, 256, 256, 64)         64        ['lambda_1[0][0]']            \n                                                                                                  \n conv2d_36 (Conv2D)          (None, 256, 256, 3)          15555     ['p_re_lu_18[0][0]']          \n                                                                                                  \n lambda_2 (Lambda)           (None, 256, 256, 3)          0         ['conv2d_36[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 1554883 (5.93 MB)\nTrainable params: 1550659 (5.92 MB)\nNon-trainable params: 4224 (16.50 KB)\n__________________________________________________________________________________________________\nModel: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n                                                                 \n conv2d_37 (Conv2D)          (None, 256, 256, 64)      1792      \n                                                                 \n leaky_re_lu (LeakyReLU)     (None, 256, 256, 64)      0         \n                                                                 \n conv2d_38 (Conv2D)          (None, 128, 128, 128)     73856     \n                                                                 \n batch_normalization_33 (Ba  (None, 128, 128, 128)     512       \n tchNormalization)                                               \n                                                                 \n leaky_re_lu_1 (LeakyReLU)   (None, 128, 128, 128)     0         \n                                                                 \n conv2d_39 (Conv2D)          (None, 128, 128, 256)     295168    \n                                                                 \n batch_normalization_34 (Ba  (None, 128, 128, 256)     1024      \n tchNormalization)                                               \n                                                                 \n leaky_re_lu_2 (LeakyReLU)   (None, 128, 128, 256)     0         \n                                                                 \n conv2d_40 (Conv2D)          (None, 64, 64, 512)       1180160   \n                                                                 \n batch_normalization_35 (Ba  (None, 64, 64, 512)       2048      \n tchNormalization)                                               \n                                                                 \n leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 512)       0         \n                                                                 \n conv2d_41 (Conv2D)          (None, 64, 64, 512)       2359808   \n                                                                 \n batch_normalization_36 (Ba  (None, 64, 64, 512)       2048      \n tchNormalization)                                               \n                                                                 \n leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 512)       0         \n                                                                 \n global_average_pooling2d (  (None, 512)               0         \n GlobalAveragePooling2D)                                         \n                                                                 \n dense (Dense)               (None, 1024)              525312    \n                                                                 \n leaky_re_lu_5 (LeakyReLU)   (None, 1024)              0         \n                                                                 \n dense_1 (Dense)             (None, 1)                 1025      \n                                                                 \n=================================================================\nTotal params: 4442753 (16.95 MB)\nTrainable params: 4439937 (16.94 MB)\nNon-trainable params: 2816 (11.00 KB)\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# We use VGG19 to extract features for the perceptual (content) loss\nvgg = keras.applications.VGG19(include_top=False,\n                               weights='imagenet',\n                               input_shape=(config.hr_height, config.hr_width, 3))\nvgg.trainable = False\n\ncontent_layer = 'block5_conv4'  # or 'block5_conv2'\ncontent_model = keras.Model(inputs=vgg.input, outputs=vgg.get_layer(content_layer).output)\ncontent_model.trainable = False\n\nprint(\"VGG19 loaded. Extracting features from:\", content_layer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:37:45.026348Z","iopub.execute_input":"2025-03-19T19:37:45.026706Z","iopub.status.idle":"2025-03-19T19:37:45.939082Z","shell.execute_reply.started":"2025-03-19T19:37:45.026677Z","shell.execute_reply":"2025-03-19T19:37:45.938303Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\nVGG19 loaded. Extracting features from: block5_conv4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Define standard TF losses in float32 for stability\nmse = tf.keras.losses.MeanSquaredError(name='mse', reduction='none')\nbce = tf.keras.losses.BinaryCrossentropy(name='bce', reduction='none')\n\n# Create Adam optimizers\ngen_optimizer = tf.keras.optimizers.Adam(learning_rate=config.gen_lr, beta_1=config.beta1)\ndisc_optimizer = tf.keras.optimizers.Adam(learning_rate=config.disc_lr, beta_1=config.beta1)\n\ndef lr_schedule(epoch, initial_lr):\n    \"\"\"\n    Simple step-down schedule. Modify if needed.\n    \"\"\"\n    if epoch < 100:\n        return initial_lr\n    elif epoch < 150:\n        return initial_lr * 0.1\n    else:\n        return initial_lr * 0.01\n\nprint(\"Optimizers and losses defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:38:10.653882Z","iopub.execute_input":"2025-03-19T19:38:10.654214Z","iopub.status.idle":"2025-03-19T19:38:10.666118Z","shell.execute_reply.started":"2025-03-19T19:38:10.654187Z","shell.execute_reply":"2025-03-19T19:38:10.665467Z"}},"outputs":[{"name":"stdout","text":"Optimizers and losses defined.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"@tf.function\ndef train_step(lr_images, hr_images):\n    \"\"\"\n    Single training step for SRGAN.\n    Returns content_loss, gen_adv_loss, disc_loss as floats.\n    \"\"\"\n    lr_images = tf.clip_by_value(lr_images, 0.0, 1.0)\n    hr_images = tf.clip_by_value(hr_images, 0.0, 1.0)\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        sr_images = generator(lr_images, training=True)\n        sr_images = tf.clip_by_value(sr_images, 0.0, 1.0)\n        \n        # Discriminator outputs\n        hr_validity = discriminator(hr_images, training=True)\n        sr_validity = discriminator(sr_images, training=True)\n\n        # Pixel loss (MSE)\n        pixel_loss = tf.reduce_mean(mse(hr_images, sr_images))\n\n        # Perceptual loss\n        hr_vgg_input = tf.cast(hr_images * 255.0, tf.float32)\n        sr_vgg_input = tf.cast(sr_images * 255.0, tf.float32)\n        hr_features = content_model(hr_vgg_input)\n        sr_features = content_model(sr_vgg_input)\n        perceptual_loss = tf.reduce_mean(tf.square(hr_features - sr_features))\n\n        # Combine to get content loss\n        content_l = pixel_loss + config.perceptual_weight * perceptual_loss\n\n        # Adversarial loss\n        disc_real_loss = tf.reduce_mean(bce(tf.ones_like(hr_validity), hr_validity))\n        disc_fake_loss = tf.reduce_mean(bce(tf.zeros_like(sr_validity), sr_validity))\n        disc_loss = 0.5 * (disc_real_loss + disc_fake_loss)\n\n        gen_adv_loss = tf.reduce_mean(bce(tf.ones_like(sr_validity), sr_validity))\n        gen_loss = content_l + config.adversarial_weight * gen_adv_loss\n\n    # Gradients\n    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    # Optional: gradient clipping\n    gen_gradients = [tf.clip_by_norm(g, 0.5) for g in gen_gradients if g is not None]\n    disc_gradients = [tf.clip_by_norm(g, 0.5) for g in disc_gradients if g is not None]\n\n    # Apply\n    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n    disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n\n    return content_l, gen_adv_loss, disc_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:51:52.578695Z","iopub.execute_input":"2025-03-19T19:51:52.579453Z","iopub.status.idle":"2025-03-19T19:51:52.803173Z","shell.execute_reply.started":"2025-03-19T19:51:52.579412Z","shell.execute_reply":"2025-03-19T19:51:52.802266Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def calculate_psnr(val_dataset, generator, num_batches=5):\n    psnr_values = []\n    batch_count = 0\n    for lr_batch, hr_batch in val_dataset:\n        sr_batch = generator(lr_batch, training=False)\n        sr_batch = tf.clip_by_value(sr_batch, 0.0, 1.0)\n        psnr_batch = tf.image.psnr(sr_batch, hr_batch, max_val=1.0)\n        psnr_values.extend(psnr_batch.numpy())\n        \n        batch_count += 1\n        if batch_count >= num_batches:\n            break\n    return float(np.mean(psnr_values)) if psnr_values else 0.0\n\n\ndef generate_and_save_images(model, epoch, val_dataset, config, show_inline=False):\n    \"\"\"\n    - ALWAYS cast to float32 before plt.imshow or plt.savefig to avoid \"Unsupported dtype\".\n    - show_inline=True => display in Jupyter cell.\n    \"\"\"\n    for lr_images, hr_images in val_dataset.take(1):\n        sr_images = model(lr_images, training=False)\n        sr_images = tf.clip_by_value(sr_images, 0.0, 1.0)\n\n        # Get first sample\n        lr_np = lr_images[0].numpy().astype('float32')\n        sr_np = sr_images[0].numpy().astype('float32')\n        hr_np = hr_images[0].numpy().astype('float32')\n\n        plt.figure(figsize=(15, 8))\n        titles = ['Low Resolution', 'Super Resolution', 'High Resolution']\n        for i, (title, img) in enumerate(zip(titles, [lr_np, sr_np, hr_np])):\n            plt.subplot(1, 3, i + 1)\n            plt.title(title)\n            # Ensure 0..1 range\n            img = np.clip(img, 0.0, 1.0)\n            plt.imshow(img)\n            plt.axis('off')\n        plt.tight_layout()\n\n        # Save\n        save_path = os.path.join(config.sample_dir, f'image_epoch_{epoch:04d}.png')\n        plt.savefig(save_path)\n        \n        if show_inline:\n            plt.show()\n        else:\n            plt.close()\n        print(f\"Saved sample SR image at: {save_path}\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:51:48.885416Z","iopub.execute_input":"2025-03-19T19:51:48.885797Z","iopub.status.idle":"2025-03-19T19:51:48.895162Z","shell.execute_reply.started":"2025-03-19T19:51:48.885773Z","shell.execute_reply":"2025-03-19T19:51:48.894027Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train(train_dataset, val_dataset, config):\n    log_file = os.path.join(config.sample_dir, 'training_log.csv')\n    with open(log_file, 'w') as f:\n        f.write('epoch,content_loss,adv_loss,disc_loss,psnr,lr\\n')\n\n    best_psnr = 0.0\n\n    for epoch in range(config.epochs):\n        # Adjust learning rates\n        new_lr = lr_schedule(epoch, config.gen_lr)\n        gen_optimizer.learning_rate.assign(new_lr)\n        disc_optimizer.learning_rate.assign(new_lr)\n\n        print(f\"\\nEpoch {epoch+1}/{config.epochs} - LR: {new_lr:.2e}\")\n        total_batches = tf.data.experimental.cardinality(train_dataset).numpy()\n        pbar = tqdm(train_dataset, total=total_batches, desc=\"Training\")\n\n        epoch_c_losses, epoch_adv_losses, epoch_d_losses = [], [], []\n\n        for (lr_img, hr_img) in pbar:\n            c_loss, adv_loss, d_loss = train_step(lr_img, hr_img)\n            epoch_c_losses.append(c_loss.numpy())\n            epoch_adv_losses.append(adv_loss.numpy())\n            epoch_d_losses.append(d_loss.numpy())\n\n        avg_c_loss = float(np.mean(epoch_c_losses))\n        avg_adv_loss = float(np.mean(epoch_adv_losses))\n        avg_d_loss = float(np.mean(epoch_d_losses))\n\n        # Evaluate PSNR on validation\n        avg_psnr = calculate_psnr(val_dataset, generator)\n\n        print(f\"[Epoch {epoch+1}] Content: {avg_c_loss:.3f} | \"\n              f\"Adv: {avg_adv_loss:.3f} | Disc: {avg_d_loss:.3f} | PSNR: {avg_psnr:.2f}\")\n\n        # Check for improvement\n        if avg_psnr > best_psnr:\n            best_psnr = avg_psnr\n            generator.save_weights(os.path.join(config.checkpoint_dir, 'generator_best.h5'))\n            discriminator.save_weights(os.path.join(config.checkpoint_dir, 'discriminator_best.h5'))\n            print(f\"New best PSNR: {best_psnr:.2f} - model saved.\")\n            # Show a sample SR image inline\n            generate_and_save_images(generator, epoch+1, val_dataset, config, show_inline=True)\n        else:\n            # Optional: generate images every 5 epochs or last\n            if (epoch+1) % 5 == 0 or (epoch+1) == config.epochs:\n                generate_and_save_images(generator, epoch+1, val_dataset, config, show_inline=False)\n\n        # Log\n        with open(log_file, 'a') as f:\n            f.write(f\"{epoch+1},{avg_c_loss},{avg_adv_loss},{avg_d_loss},{avg_psnr},{new_lr}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:40:42.771603Z","iopub.execute_input":"2025-03-19T19:40:42.771979Z","iopub.status.idle":"2025-03-19T19:40:42.781477Z","shell.execute_reply.started":"2025-03-19T19:40:42.771955Z","shell.execute_reply":"2025-03-19T19:40:42.780620Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Set how many epochs to train\nconfig.epochs = 200\n\n# Kick off training\ntrain(train_dataset, val_dataset, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T19:53:06.221679Z","iopub.execute_input":"2025-03-19T19:53:06.222362Z","iopub.status.idle":"2025-03-19T20:04:03.065092Z","shell.execute_reply.started":"2025-03-19T19:53:06.222321Z","shell.execute_reply":"2025-03-19T20:04:03.063945Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [01:02<00:00,  1.24s/it]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Content: inf | Adv: 5.261719 | Disc: 0.015175 | PSNR: 11.21\nNew best PSNR: 11.21. Saved model weights.\n\nEpoch 2/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Content: inf | Adv: 5.566406 | Disc: 0.015572 | PSNR: 11.10\n\nEpoch 3/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Content: inf | Adv: 5.609375 | Disc: 0.015671 | PSNR: 11.25\nNew best PSNR: 11.25. Saved model weights.\n\nEpoch 4/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Content: inf | Adv: 6.042969 | Disc: 0.011726 | PSNR: 11.15\n\nEpoch 5/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Content: inf | Adv: 6.019531 | Disc: 0.016388 | PSNR: 11.14\nSaved sample SR image at: samples/image_epoch_0005.png\n\nEpoch 6/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Content: inf | Adv: 6.214844 | Disc: 0.012695 | PSNR: 11.09\n\nEpoch 7/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Content: inf | Adv: 6.816406 | Disc: 0.008202 | PSNR: 11.06\n\nEpoch 8/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Content: inf | Adv: 6.777344 | Disc: 0.010857 | PSNR: 10.95\n\nEpoch 9/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Content: inf | Adv: 7.089844 | Disc: 0.008064 | PSNR: 10.92\n\nEpoch 10/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Content: inf | Adv: 7.246094 | Disc: 0.006577 | PSNR: 10.92\nSaved sample SR image at: samples/image_epoch_0010.png\n\nEpoch 11/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Content: inf | Adv: 7.667969 | Disc: 0.007328 | PSNR: 10.86\n\nEpoch 12/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Content: inf | Adv: 7.507812 | Disc: 0.012024 | PSNR: 10.80\n\nEpoch 13/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Content: inf | Adv: 7.421875 | Disc: 0.010193 | PSNR: 10.76\n\nEpoch 14/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Content: inf | Adv: 7.894531 | Disc: 0.011055 | PSNR: 10.74\n\nEpoch 15/200 - LR: 1.00e-04\n","output_type":"stream"},{"name":"stderr","text":"Training:  60%|██████    | 30/50 [00:25<00:17,  1.17it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m config\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Kick off training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dataset, val_dataset, config)\u001b[0m\n\u001b[1;32m     24\u001b[0m epoch_disc_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr_images, hr_images \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m---> 27\u001b[0m     c_loss, a_loss, d_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     epoch_content_losses\u001b[38;5;241m.\u001b[39mappend(c_loss\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     29\u001b[0m     epoch_adv_losses\u001b[38;5;241m.\u001b[39mappend(a_loss\u001b[38;5;241m.\u001b[39mnumpy())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14}]}